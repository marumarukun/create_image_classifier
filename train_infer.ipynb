{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marumarukun/Documents/create_img_clf/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm   \n",
    "\n",
    "from src.utils import seed_everything\n",
    "from src.model import MyNet\n",
    "from src.dataset import CustomDataset\n",
    "from src.transform import define_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_DIR: str = Path(\"data/train\")\n",
    "VALID_IMAGE_DIR: str = Path(\"data/valid\")\n",
    "LABEL_DICT: dict = {\"helmet\": 0, \"head\": 1}\n",
    "\n",
    "IMAGE_SIZE: int = 224\n",
    "NUM_CLASSES: int = len(LABEL_DICT)\n",
    "MODEL_NAME: str = \"mobilenetv3_large_100.ra_in1k\"\n",
    "PRETRAINED: bool = True\n",
    "\n",
    "BATCH_SIZE: int = 32\n",
    "NUM_WORKERS: int = 4\n",
    "NUM_EPOCHS: int = 10\n",
    "\n",
    "LR: float = 1e-3\n",
    "MOMENTUM: float = 0.99\n",
    "WEIGHT_DECAY: float = 1e-4\n",
    "\n",
    "SEED: int = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed値の固定\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (model): MobileNetV3(\n",
      "    (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNormAct2d(\n",
      "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): Identity()\n",
      "          (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): ReLU(inplace=True)\n",
      "            (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Hardsigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): ConvBnAct(\n",
      "          (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Hardswish()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act2): Hardswish()\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (classifier): Linear(in_features=1280, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = MyNet(model_name=MODEL_NAME, num_classes=NUM_CLASSES, pretrained=PRETRAINED)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_head_image: 87842\n",
      "num_train_helmet_image: 7342\n",
      "num_valid_head_image: 23491\n",
      "num_valid_helmet_image: 1700\n"
     ]
    }
   ],
   "source": [
    "num_train_head_image = len(list(TRAIN_IMAGE_DIR.glob('head/*.jpg')))\n",
    "num_train_helmet_image = len(list(TRAIN_IMAGE_DIR.glob('helmet/*.jpg')))\n",
    "num_valid_head_image = len(list(VALID_IMAGE_DIR.glob('head/*.jpg')))\n",
    "num_valid_helmet_image = len(list(VALID_IMAGE_DIR.glob('helmet/*.jpg')))\n",
    "\n",
    "print(f\"num_train_head_image: {num_train_head_image}\")\n",
    "print(f\"num_train_helmet_image: {num_train_helmet_image}\")\n",
    "print(f\"num_valid_head_image: {num_valid_head_image}\")\n",
    "print(f\"num_valid_helmet_image: {num_valid_helmet_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_head_path_list: 7342\n",
      "train_helmet_path_list: 7342\n",
      "valid_head_path_list: 1700\n",
      "valid_helmet_path_list: 1700\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_head_path_list = list(TRAIN_IMAGE_DIR.glob('head/*.jpg'))\n",
    "train_helmet_path_list = list(TRAIN_IMAGE_DIR.glob('helmet/*.jpg'))\n",
    "valid_head_path_list = list(VALID_IMAGE_DIR.glob('head/*.jpg'))\n",
    "valid_helmet_path_list = list(VALID_IMAGE_DIR.glob('helmet/*.jpg'))\n",
    "\n",
    "train_head_path_list = train_head_path_list[:min(num_train_head_image, num_train_helmet_image)]\n",
    "train_helmet_path_list = train_helmet_path_list[:min(num_train_head_image, num_train_helmet_image)]\n",
    "valid_head_path_list = valid_head_path_list[:min(num_valid_head_image, num_valid_helmet_image)]\n",
    "valid_helmet_path_list = valid_helmet_path_list[:min(num_valid_head_image, num_valid_helmet_image)]\n",
    "# 動作テスト用に100枚ずつに制限する\n",
    "# train_head_path_list = train_head_path_list[:100]\n",
    "# train_helmet_path_list = train_helmet_path_list[:100]\n",
    "# valid_head_path_list = valid_head_path_list[:100]\n",
    "# valid_helmet_path_list = valid_helmet_path_list[:100]\n",
    "\n",
    "print(f\"train_head_path_list: {len(train_head_path_list)}\")\n",
    "print(f\"train_helmet_path_list: {len(train_helmet_path_list)}\")\n",
    "print(f\"valid_head_path_list: {len(valid_head_path_list)}\")\n",
    "print(f\"valid_helmet_path_list: {len(valid_helmet_path_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データと正解ラベルの取得\n",
    "# train_image_path_list = list(TRAIN_IMAGE_DIR.glob(\"*/*.jpg\"))\n",
    "# valid_image_path_list = list(VALID_IMAGE_DIR.glob(\"*/*.jpg\"))\n",
    "train_image_path_list = train_head_path_list + train_helmet_path_list\n",
    "valid_image_path_list = valid_head_path_list + valid_helmet_path_list\n",
    "train_label_list = [LABEL_DICT[path.parent.name] for path in train_image_path_list]\n",
    "valid_label_list = [LABEL_DICT[path.parent.name] for path in valid_image_path_list]\n",
    "\n",
    "# Datasetの作成\n",
    "train_dataset = CustomDataset(\n",
    "    image_path_list=train_image_path_list,\n",
    "    label_list=train_label_list,\n",
    "    transform=define_transforms(IMAGE_SIZE)['train']\n",
    ")\n",
    "valid_dataset = CustomDataset(\n",
    "    image_path_list=valid_image_path_list,\n",
    "    label_list=valid_label_list,\n",
    "    transform=define_transforms(IMAGE_SIZE)['valid']\n",
    ")\n",
    "\n",
    "# DataLoaderの作成\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# macで実行する場合は以下コメントアウト解除\n",
    "device = torch.device(\"mps\"if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# 最適化手法の設定\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=LR,\n",
    "#     momentum=MOMENTUM,\n",
    "#     weight_decay=WEIGHT_DECAY\n",
    "# )\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    ")\n",
    "\n",
    "# スケジューラーの設定\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCHS,\n",
    "    eta_min=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/458 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 458/458 [03:59<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, valid_loss: 0.12995676170614268\n",
      "!!!update best loss & save best model!!!\n",
      "epoch: 1, accuracy: 0.9602941176470589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/458 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # 学習\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # データをデバイスに転送\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 順伝播\n",
    "        output = model(images)\n",
    "        \n",
    "        # 損失の計算\n",
    "        train_loss = criterion(output, labels)\n",
    "        \n",
    "        # 逆伝播\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "\n",
    "    # 検証\n",
    "    model.eval()\n",
    "    gt_label_list = []\n",
    "    pred_label_list = []\n",
    "    valid_loss_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            # データをデバイスに転送\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 順伝播\n",
    "            output = model(images)\n",
    "            \n",
    "            # 損失の計算\n",
    "            valid_loss = criterion(output, labels)\n",
    "            valid_loss_list.append(valid_loss.item())\n",
    "            \n",
    "            # 予測ラベルの取得\n",
    "            pred_labels = output.argmax(dim=1)\n",
    "            gt_label_list.extend(labels.cpu().numpy())\n",
    "            pred_label_list.extend(pred_labels.cpu().numpy())\n",
    "            \n",
    "    valid_loss_mean = np.mean(valid_loss_list)\n",
    "    print(f\"epoch: {epoch+1}, valid_loss: {valid_loss_mean}\")\n",
    "    \n",
    "    # lossが改善した場合にモデルを保存\n",
    "    if valid_loss_mean < best_loss:\n",
    "        best_loss = valid_loss_mean\n",
    "        torch.save(model.state_dict(), f\"{MODEL_NAME}.pth\")\n",
    "        print(\"!!!update best loss & save best model!!!\")\n",
    "    \n",
    "    gt_label_array = np.array(gt_label_list)\n",
    "    pred_label_array = np.array(pred_label_list)\n",
    "    accuracy = (gt_label_array == pred_label_array).mean()\n",
    "    print(f\"epoch: {epoch+1}, accuracy: {accuracy}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n",
      "1771\n"
     ]
    }
   ],
   "source": [
    "print(sum(gt_label_array))\n",
    "print(sum(pred_label_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "# モデルを評価モードに設定\n",
    "model.eval()\n",
    "\n",
    "# ダミー入力を作成\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "# ONNX形式に変換\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"onnx/mobilenetv3_under_sampling.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11,\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}},\n",
    ")\n",
    "\n",
    "# 型の推定\n",
    "model = onnx.load(\"onnx/mobilenetv3_under_sampling.onnx\")\n",
    "model = onnx.shape_inference.infer_shapes(model)\n",
    "\n",
    "# モデル構造の最適化\n",
    "model_simp, check = simplify(model)\n",
    "\n",
    "onnx.save(model_simp, \"onnx/mobilenetv3_under_sampling.onnx\")\n",
    "\n",
    "print(\"Model converted to ONNX format.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
